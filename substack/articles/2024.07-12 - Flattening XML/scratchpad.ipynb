{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xmltodict\n",
    "import xmltodict\n",
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_xml_to_csv(xml_file: str, csv_file_path: str) -> None:\n",
    "\n",
    "    xml_payload = ''\n",
    "\n",
    "    with open(xml_file, 'r', encoding='utf-8') as xf:\n",
    "        xml_payload = xf.read()\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        if xml_payload.index('?>'):\n",
    "            dec_end = xml_payload.index('?>')+2\n",
    "            xml_payload = xml_payload[dec_end:]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    #print(xml_payload)\n",
    "\n",
    "    xd = xmltodict.parse(xml_payload)\n",
    "\n",
    "    def flatten_array(arr: list, parent_key = '', sep = '/'):\n",
    "        items = []\n",
    "        for i, val in enumerate(arr):\n",
    "            if isinstance(val, dict):\n",
    "                items.extend(flatten_dict(val, f\"{parent_key}[{i}]\", sep=sep).item())\n",
    "            elif isinstance(val, list):\n",
    "                items.extend(flatten_array(val, f\"{parent_key}[{i}]\", sep=sep))\n",
    "            else:\n",
    "                items.append((f\"{parent_key}[{i}]\", val))\n",
    "\n",
    "        return items\n",
    "    \n",
    "    def flatten_dict(d: dict, parent_key='', sep='/'):\n",
    "        items = []\n",
    "        for k, v in d.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            if isinstance(v, dict) and len(v) == 1 and list(v.keys())[0].startswith(\"@\"):\n",
    "                attr_key = f\"{new_key}/{list(v.keys())[0][1:]}\"\n",
    "                items.append((attr_key, list(v.values())[0]))\n",
    "            elif isinstance(v, dict):\n",
    "                items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "            elif isinstance(v, list):\n",
    "                for i, val in enumerate(v):\n",
    "                    if isinstance(val, dict):\n",
    "                        items.extend(flatten_dict(val, f\"{new_key}[{i}]\", sep=sep).items())\n",
    "                    elif isinstance(val, list):\n",
    "                        items.extend(flatten_array(val, f\"{new_key}[{i}]\",sep=sep))\n",
    "                    else:\n",
    "                        items.append((f\"{new_key}[{i}]\",val))\n",
    "            else:\n",
    "                items.append((new_key, v))\n",
    "\n",
    "        return dict(items)\n",
    "    \n",
    "\n",
    "    data = flatten_dict(xd)\n",
    "\n",
    "    if \"~\" in csv_file_path:\n",
    "        csv_file_path = os.path.expanduser(csv_file_path)\n",
    "\n",
    "    #print(csv_file_path)\n",
    "\n",
    "    with open(csv_file_path, 'w', newline='') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "\n",
    "        headers = [\"Path\", \"Value\"]\n",
    "        csv_writer.writerow(headers)\n",
    "\n",
    "        for k, v in data.items():\n",
    "            csv_writer.writerow([k,v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def states_simple_xml():\n",
    "    import xml.etree.ElementTree as ET\n",
    "    from xml.dom.minidom import parseString\n",
    "\n",
    "    root = ET.Element(\"states\")\n",
    "\n",
    "    data = [\n",
    "        {\"name\": \"Georgia\", \"nickname\": \"Peach State\", \"population\": \"10711908\", \"largest_city\": \"Atlanta\", \"land_mass_sqmi\": \"57906\"},\n",
    "        {\"name\": \"California\", \"nickname\": \"Granola State\", \"population\": \"39538223\", \"largest_city\": \"Los Angeles\", \"land_mass_sqmi\": \"163696\"},\n",
    "    ]\n",
    "\n",
    "    for state in data:\n",
    "\n",
    "        root = ET.Element(\"states\")\n",
    "        state_element = ET.SubElement(root, \"state\")\n",
    "        name_element = ET.SubElement(state_element, \"name\")\n",
    "        name_element.text = state[\"name\"]\n",
    "        population_element = ET.SubElement(state_element, \"population\")\n",
    "        population_element.text = state[\"population\"]\n",
    "        city_element = ET.SubElement(state_element, \"largest_city\")\n",
    "        city_element.text = state[\"largest_city\"]\n",
    "        land_mass_element = ET.SubElement(state_element, \"land_mass_sqmi\")\n",
    "        land_mass_element.text = state[\"land_mass_sqmi\"]\n",
    "\n",
    "        # Convert the ElementTree to a string\n",
    "        rough_string = ET.tostring(root, encoding=\"utf-8\")\n",
    "        # Parse the string with minidom for pretty printing\n",
    "        reparsed = parseString(rough_string)\n",
    "        pretty_xml_as_string = reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "        # Write the pretty-printed XML to a file\n",
    "        with open(f\"./files/{state['name']}.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pretty_xml_as_string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_simple_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def states_complex_xml():\n",
    "    import xml.etree.ElementTree as ET\n",
    "    from xml.dom.minidom import parseString\n",
    "\n",
    "    root = ET.Element(\"states\")\n",
    "\n",
    "    data = [\n",
    "        {\"name\": \"Georgia\", \"nickname\": \"Peach State\", \"population\": \"10711908\", \"largest_city\": \"Atlanta\", \"land_mass_sqmi\": \"57906\", \"misc\": [{\"climate\": \"warm\"}, {\"state_flower\": \"Cherokee Rose\"}]},\n",
    "        {\"name\": \"California\", \"nickname\": \"Granola State\", \"population\": \"39538223\", \"largest_city\": \"Los Angeles\", \"land_mass_sqmi\": \"163696\", \"water_sqmi\": \"7737\", \"misc\":[{\"bird\":\"California Quail\"}]},\n",
    "    ]\n",
    "\n",
    "    for state in data:\n",
    "        root = ET.Element(\"states\")\n",
    "        state_element = ET.SubElement(root, \"state\")\n",
    "        attributes = {\"nickname\": state[\"nickname\"]}\n",
    "        name_element = ET.SubElement(state_element, \"name\", **attributes)\n",
    "        name_element.text = state[\"name\"]\n",
    "        population_element = ET.SubElement(state_element, \"population\")\n",
    "        population_element.text = state[\"population\"]\n",
    "        city_element = ET.SubElement(state_element, \"largest_city\")\n",
    "        city_element.text = state[\"largest_city\"]\n",
    "        land_mass_element = ET.SubElement(state_element, \"land_mass_sqmi\")\n",
    "        land_mass_element.text = state[\"land_mass_sqmi\"]\n",
    "        if \"water_sqmi\" in state:\n",
    "            water_mass_element = ET.SubElement(state_element, \"water_sqmi\")\n",
    "            water_mass_element.text = state[\"water_sqmi\"]\n",
    "        if \"misc\" in state:\n",
    "            misc_el = ET.SubElement(state_element, \"misc\")\n",
    "            for misc_item in state['misc']:\n",
    "                for key, value in misc_item.items():\n",
    "                    misc_sub_el = ET.SubElement(misc_el, key)\n",
    "                    misc_sub_el.text = value\n",
    "\n",
    "        # Convert the ElementTree to a string\n",
    "        rough_string = ET.tostring(root, encoding=\"utf-8\")\n",
    "        # Parse the string with minidom for pretty printing\n",
    "        reparsed = parseString(rough_string)\n",
    "        pretty_xml_as_string = reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "        # Write the pretty-printed XML to a file\n",
    "        with open(f\"./files/{state['name']}_complex.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pretty_xml_as_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_simple_xml()\n",
    "states_complex_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = ['./files/California.xml', './files/Georgia.xml', './files/California_complex.xml', './files/Georgia_complex.xml']\n",
    "\n",
    "for file_path in files:\n",
    "    directory, fname = os.path.split(file_path)\n",
    "    csv_path = os.path.join(directory, fname.replace('xml','csv'))\n",
    "    flatten_xml_to_csv(file_path, csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name  population largest_city  land_mass_sqmi\n",
      "0  California    39538223  Los Angeles          163696\n",
      "1     Georgia    10711908      Atlanta           57906\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "f_pattern = './files/*_simple.xml'\n",
    "file_paths = glob.glob(f_pattern)\n",
    "df_list = [pd.read_xml(file_path) for file_path in file_paths]\n",
    "df_stacked = pd.concat(df_list, ignore_index=True)\n",
    "print(df_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name  population largest_city  land_mass_sqmi      misc  water_sqmi\n",
      "0     Georgia    10711908      Atlanta           57906  \\n               NaN\n",
      "1  California    39538223  Los Angeles          163696  \\n            7737.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_xml('./files/states_complex.xml')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   land_size            name  population           city\n",
      "0     423967      California    39538223    Los Angeles\n",
      "1     695662           Texas    29145505        Houston\n",
      "2     170312         Florida    21538187          Miami\n",
      "3     141297        New York    20201249  New York City\n",
      "4     119280    Pennsylvania    13002700   Philadelphia\n",
      "5     149995        Illinois    12812508        Chicago\n",
      "6     116096            Ohio    11799448       Columbus\n",
      "7     153910         Georgia    10711908        Atlanta\n",
      "8     139391  North Carolina    10439388      Charlotte\n",
      "9     250487        Michigan    10077331        Detroit\n",
      "Data has been written to ./files/states3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the XML file\n",
    "xml_file = './files/states2.xml'\n",
    "df = pd.read_xml(xml_file)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file = './files/states3.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"Data has been written to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmartin/dream_machine/substack/articles/2024.07-12 - Flattening XML/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 rows into test_ds.states_flat from ./files/California.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmartin/dream_machine/substack/articles/2024.07-12 - Flattening XML/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 rows into test_ds.states_flat from ./files/Georgia.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "def load_csv_to_bigquery(file_path, table_id):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    df['filename'] = filename\n",
    "\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
    "        create_disposition=bigquery.CreateDisposition.CREATE_IF_NEEDED\n",
    "    \n",
    "    )\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "\n",
    "    # Wait for the load job to complete\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Loaded {df.shape[0]} rows into {table_id} from {file_path}\")\n",
    "\n",
    "def main():\n",
    "    # Paths to your CSV files\n",
    "    csv_files = ['./files/California.csv', './files/Georgia.csv']\n",
    "    table_id = 'test_ds.states_flat'  # Replace with your project ID, dataset ID, and table ID\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        load_csv_to_bigquery(csv_file, table_id)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
