{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_version = \"3.5\"\n",
    "scala_version = \"2.12\"\n",
    "iceberg_version = \"1.7.0\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_date, rand, floor, expr\n",
    "\n",
    "catalog_name = \"iceberg\"\n",
    "warehouse_path = \"./icehouse\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"feature_flag_stuff\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.type\", \"hadoop\") \\\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", warehouse_path) \\\n",
    "    .config(\"spark.jars.packages\", f\"org.apache.iceberg:iceberg-spark-runtime-{spark_version}_{scala_version}:{iceberg_version}\") \\\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "namespace = \"test_ns\"\n",
    "spark.sql(f\"create namespace {namespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0016b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "include_last_upd_ts = config['features']['last_upd_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "        create or replace table {catalog_name}.{namespace}.stocks\n",
    "        using iceberg\n",
    "        as\n",
    "        select 'MSFT' as ticker_symbol, 23.99 as price\n",
    "        union all\n",
    "        select 'SNOW', 34.99 as price\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2fd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|ticker_symbol|price|\n",
      "+-------------+-----+\n",
      "|         MSFT|23.99|\n",
      "|         SNOW|34.99|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"select * from {catalog_name}.{namespace}.stocks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f0f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    select 'MSFT' as ticker_symbol, 21.45 as price\n",
    "\"\"\")\n",
    "df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2c293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the column does not exist\n",
    "if include_last_upd_ts:\n",
    "    cols = spark.table(f\"{catalog_name}.{namespace}.stocks\").columns\n",
    "    if \"last_upd_ts\" not in cols:\n",
    "        spark.sql(f\"ALTER TABLE {catalog_name}.{namespace}.stocks add column last_upd_ts timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987e111a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_predicate = \"\"\"\n",
    "    WHEN MATCHED THEN UPDATE set tgt.price = src.price\n",
    "\"\"\"\n",
    "if include_last_upd_ts:\n",
    "    update_predicate += \", last_upd_ts = CURRENT_TIMESTAMP\"\n",
    "\n",
    "insert_predicate = \"\"\"\n",
    "    WHEN NOT MATCHED THEN INSERT (ticker_symbol, price\n",
    "\"\"\"\n",
    "if include_last_upd_ts:\n",
    "    insert_predicate += \", last_upd_ts\"\n",
    "insert_predicate += \") VALUES (src.ticker_symbol, src.price \"\n",
    "if include_last_upd_ts:\n",
    "    insert_predicate += \", CURRENT_TIMESTAMP\"\n",
    "insert_predicate += \")\"\n",
    "\n",
    "\n",
    "sql_template = f\"\"\"\n",
    "    MERGE INTO {catalog_name}.{namespace}.stocks as tgt\n",
    "        USING data as src\n",
    "            on tgt.ticker_symbol = src.ticker_symbol\n",
    "        {update_predicate}\n",
    "        {insert_predicate}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#for historical backfill\n",
    "if include_last_upd_ts:\n",
    "    sql_template += \"\\nWHEN NOT MATCHED BY SOURCE THEN UPDATE SET last_upd_ts = current_timestamp\"\n",
    "\n",
    "spark.sql(sql_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1bcd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+--------------------------+\n",
      "|ticker_symbol|price|last_upd_ts               |\n",
      "+-------------+-----+--------------------------+\n",
      "|MSFT         |21.45|2025-05-07 08:42:41.972674|\n",
      "|SNOW         |34.99|2025-05-07 08:42:41.972674|\n",
      "+-------------+-----+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"select * from {catalog_name}.{namespace}.stocks\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
