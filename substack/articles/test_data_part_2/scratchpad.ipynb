{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Data Generation\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"8\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from pyspark.sql.functions import current_date, rand, floor, udf\n",
    "from pyspark.sql.types import StringType\n",
    "row_cnt = 500_000_000\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "f_path = os.path.join(home_dir, f\"test_dummy_data/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create dataset: 6.61 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#just a rowID: 6 seconds for just row id\n",
    "start_ts = time.time()\n",
    "df = spark.range(0, row_cnt).toDF('row_id') \n",
    "df.write.mode('overwrite').parquet(f_path)\n",
    "end_ts = time.time()\n",
    "print(f\"Total time to create dataset: {end_ts - start_ts:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create dataset: 8.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#rowID plus current date: 8 seconds adding current date\n",
    "start_ts = time.time()\n",
    "df = spark.range(0, row_cnt) \\\n",
    "    .withColumn('row_id',current_date()) \\\n",
    "    .toDF('row_id', 'rpt_dt') \\\n",
    "    .write.mode('overwrite').parquet(f_path) \n",
    "#df.write.mode('overwrite').parquet(f_path)\n",
    "end_ts = time.time()\n",
    "print(f\"Total time to create dataset: {end_ts - start_ts:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+\n",
      "|row_id|    rpt_dt|some_val|\n",
      "+------+----------+--------+\n",
      "|     0|2024-06-06|      16|\n",
      "|     1|2024-06-06|       0|\n",
      "|     2|2024-06-06|      59|\n",
      "|     3|2024-06-06|      12|\n",
      "|     4|2024-06-06|      70|\n",
      "+------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create dataset: 11.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#add a random int: 12 seconds\n",
    "\n",
    "start_ts = time.time()\n",
    "\n",
    "df = spark.range(0, row_cnt) \\\n",
    "    .withColumn('rpt_dt', current_date()) \\\n",
    "    .withColumn('some_val', floor(rand() * 100)) \\\n",
    "    .withColumnRenamed('id', 'row_id') \\\n",
    "    .toDF('row_id', 'rpt_dt', 'some_val') \n",
    "\n",
    "df.show(5)\n",
    "df.write.mode('overwrite').parquet(f_path)  \n",
    "end_ts = time.time()\n",
    "print(f\"Total time to create dataset: {end_ts - start_ts:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+--------------------+\n",
      "|row_id|    rpt_dt|some_val|             txn_key|\n",
      "+------+----------+--------+--------------------+\n",
      "|     0|2024-06-06|      77|4964a611-5984-433...|\n",
      "|     1|2024-06-06|      37|6bce99e6-879d-424...|\n",
      "|     2|2024-06-06|      22|3e53e424-ae2d-4c5...|\n",
      "|     3|2024-06-06|      25|690e8d82-be27-4d6...|\n",
      "|     4|2024-06-06|      26|8260cdc6-f1e2-4c6...|\n",
      "+------+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create dataset: 247.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#add guid: adds a whopping extra 240 seconds....UDFS in spark are Terrible\n",
    "@udf(StringType())\n",
    "def generate_uuid():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "start_ts = time.time()\n",
    "\n",
    "df = spark.range(0, row_cnt) \\\n",
    "    .withColumn('rpt_dt', current_date()) \\\n",
    "    .withColumn('some_val', floor(rand() * 100)) \\\n",
    "    .withColumn(\"txn_key\", generate_uuid()) \\\n",
    "    .withColumnRenamed('id', 'row_id') \\\n",
    "    .toDF('row_id', 'rpt_dt', 'some_val', 'txn_key') \n",
    "\n",
    "df.show(5)\n",
    "df.write.mode('overwrite').parquet(f_path)  \n",
    "end_ts = time.time()\n",
    "print(f\"Total time to create dataset: {end_ts - start_ts:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+--------------------+\n",
      "|row_id|    rpt_dt|some_val|             txn_key|\n",
      "+------+----------+--------+--------------------+\n",
      "|     0|2024-06-06|      45|a6263713-a1b6-4b6...|\n",
      "|     1|2024-06-06|      67|69ea866b-9cdf-474...|\n",
      "|     2|2024-06-06|      47|12e7a895-997c-438...|\n",
      "|     3|2024-06-06|      74|adb80dc3-17c4-4f5...|\n",
      "|     4|2024-06-06|       3|17a326c2-942a-4ea...|\n",
      "+------+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create dataset: 26.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#add guid via inliniing: 26.22 seconds\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "start_ts = time.time()\n",
    "\n",
    "df = spark.range(0, row_cnt) \\\n",
    "    .withColumn('rpt_dt', current_date()) \\\n",
    "    .withColumn('some_val', floor(rand() * 100)) \\\n",
    "    .withColumn(\"txn_key\", expr(\"uuid()\")) \\\n",
    "    .withColumnRenamed('id', 'row_id') \\\n",
    "    .toDF('row_id', 'rpt_dt', 'some_val', 'txn_key') \n",
    "\n",
    "df.show(5)\n",
    "df.write.mode('overwrite').parquet(f_path)  \n",
    "end_ts = time.time()\n",
    "print(f\"Total time to create dataset: {end_ts - start_ts:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
