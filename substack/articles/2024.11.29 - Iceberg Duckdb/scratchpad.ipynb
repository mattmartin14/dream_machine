{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyspark duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_version = \"3.5\"\n",
    "scala_version = \"2.12\"\n",
    "iceberg_version = \"1.7.0\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_date, rand, floor, expr\n",
    "\n",
    "catalog_name = \"iceberg\"\n",
    "warehouse_path = \"./icehouse\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"local_iceberg_example\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.type\", \"hadoop\") \\\n",
    "    .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", warehouse_path) \\\n",
    "    .config(\"spark.jars.packages\", f\"org.apache.iceberg:iceberg-spark-runtime-{spark_version}_{scala_version}:{iceberg_version}\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_cnt = 5_000\n",
    "df = spark.range(0, row_cnt) \\\n",
    "    .withColumn('rpt_dt', current_date()) \\\n",
    "    .withColumn('some_val', floor(rand() * 100)) \\\n",
    "    .withColumn(\"txn_key\", expr(\"uuid()\")) \\\n",
    "    .withColumnRenamed('id', 'row_id') \\\n",
    "    .toDF('row_id', 'rpt_dt', 'some_val', 'txn_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespace = \"dummy_ns\"\n",
    "spark.sql(f\"create namespace {namespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"dummy_data\"\n",
    "\n",
    "df.writeTo(f\"{catalog_name}.{namespace}.{table_name}\") \\\n",
    "    .using(\"iceberg\") \\\n",
    "    .createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "create or replace table {catalog_name}.{namespace}.dummy_data2\n",
    "using iceberg\n",
    "as \n",
    "select * from {catalog_name}.{namespace}.dummy_data\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "    MERGE INTO {catalog_name}.{namespace}.dummy_data2 as tgt\n",
    "        USING {catalog_name}.{namespace}.dummy_data as src\n",
    "            on tgt.row_id = src.row_id\n",
    "        WHEN MATCHED THEN UPDATE\n",
    "            set tgt.txn_key = src.txn_key, tgt.some_val = 12345\n",
    "        WHEN NOT MATCHED THEN INSERT (row_id, rpt_dt, some_val, txn_key)\n",
    "        VALUES (src.row_id, src.rpt_dt, src.some_val, src.txn_key)\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x10e4539f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "cn = duckdb.connect()\n",
    "cn.execute(\"\"\"\n",
    "INSTALL iceberg;\n",
    "LOAD iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬────────────┬──────────┬──────────────────────────────────────┐\n",
      "│ row_id │   rpt_dt   │ some_val │               txn_key                │\n",
      "│ int64  │    date    │  int64   │               varchar                │\n",
      "├────────┼────────────┼──────────┼──────────────────────────────────────┤\n",
      "│      0 │ 2024-11-29 │       92 │ 26248dcd-e7c6-441c-ab1c-ced851b7b49d │\n",
      "│      1 │ 2024-11-29 │        5 │ d43e6d75-68d6-456a-912c-8ff6edc4eb3c │\n",
      "│      2 │ 2024-11-29 │       74 │ 27d60a81-a162-4985-8459-fa83a12ea6d2 │\n",
      "│      3 │ 2024-11-29 │       62 │ 8cd3e1ed-bb4c-4cb0-84ff-06c6ddb3d89a │\n",
      "│      4 │ 2024-11-29 │       58 │ 8cefb363-e8f1-4fc2-9592-b6cef9cba3d7 │\n",
      "│      5 │ 2024-11-29 │       25 │ 896313f1-6eb3-47c8-98db-8e28d521de5f │\n",
      "│      6 │ 2024-11-29 │       64 │ 9e50253c-ceef-4d51-aa36-c8d6ec81d038 │\n",
      "│      7 │ 2024-11-29 │        7 │ 19fc3860-5746-4c85-b52f-49bde67879c6 │\n",
      "│      8 │ 2024-11-29 │       63 │ dba3df3b-6c36-4593-bbac-049db8ad4b81 │\n",
      "│      9 │ 2024-11-29 │       50 │ dae8e79d-db0b-443f-a3fa-d9ccea8f183f │\n",
      "├────────┴────────────┴──────────┴──────────────────────────────────────┤\n",
      "│ 10 rows                                                     4 columns │\n",
      "└───────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cn.sql(f\"\"\"\n",
    "    select *\n",
    "    from iceberg_scan('{warehouse_path}/{namespace}/{table_name}')\n",
    "    limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the trash\n",
    "spark.sql(f\"drop table {catalog_name}.{namespace}.{table_name} purge\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
