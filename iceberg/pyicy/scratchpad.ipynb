{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cn.execute(\"select 1 as x\").arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: int32\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sqlalchemy pyarrow pyiceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes as of 9/3/2024\n",
    "this is all still a hot mess.\n",
    "\n",
    "looks like this is a decent tutorial though [link](https://medium.com/@tglawless/getting-started-with-pyiceberg-a2fc1caffdab)\n",
    "\n",
    "i think the kicker is i should make a yaml file with my iceberg warehouse config like the tutorial did above.\n",
    "\n",
    "then when setting up the catalog with (\"local\") as the catalog, it will grab the yaml config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import StringType, IntegerType\n",
    "from pyiceberg.schema import Field, NestedField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "        NestedField(field_id=1, name=\"name\", field_type=StringType(), required=True),\n",
    "        NestedField(field_id=2, name=\"age\", field_type=IntegerType(), required=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_path = \"./icehouse\"\n",
    "catalog = load_catalog(name=\"local\", uri=f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\", warehouse=f\"file://{warehouse_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.create_namespace_if_not_exists(\"junk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_table = catalog.create_table_if_not_exists(identifier=\"junk.dummy_table\",schema=schema, location=warehouse_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "PyIceberg still seems to be very much in its infancy\n",
    "- creating an iceberg table requires sqlalchemy\n",
    "- the tables generated do not play nice with the duckdb extension\n",
    "- when trying to query an iceberg table written by pyiceberg in duckdb, duckdb is looking for several addtional files that pyiceberg does not generate such as a \"version-hint.txt\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "\n",
    "warehouse_path = \"./icehouse\"\n",
    "catalog = SqlCatalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        \"uri\": f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\",\n",
    "        \"warehouse\": f\"file://{warehouse_path}\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "output_path = \"./yellow_tripdata_2023-01.parquet\"\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(output_path, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "df = pq.read_table(\"/tmp/yellow_tripdata_2023-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID: int64\n",
      "tpep_pickup_datetime: timestamp[us]\n",
      "tpep_dropoff_datetime: timestamp[us]\n",
      "passenger_count: double\n",
      "trip_distance: double\n",
      "RatecodeID: double\n",
      "store_and_fwd_flag: string\n",
      "PULocationID: int64\n",
      "DOLocationID: int64\n",
      "payment_type: int64\n",
      "fare_amount: double\n",
      "extra: double\n",
      "mta_tax: double\n",
      "tip_amount: double\n",
      "tolls_amount: double\n",
      "improvement_surcharge: double\n",
      "total_amount: double\n",
      "congestion_surcharge: double\n",
      "airport_fee: double\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 2492\n"
     ]
    }
   ],
   "source": [
    "print(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NamespaceAlreadyExistsError",
     "evalue": "Namespace default already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNamespaceAlreadyExistsError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_namespace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m table \u001b[38;5;241m=\u001b[39m catalog\u001b[38;5;241m.\u001b[39mcreate_table(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault.taxi_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     schema\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mschema,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/dream_machine/iceberg/pyicy/.venv/lib/python3.11/site-packages/pyiceberg/catalog/sql.py:527\u001b[0m, in \u001b[0;36mSqlCatalog.create_namespace\u001b[0;34m(self, namespace, properties)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a namespace in the catalog.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03m    NamespaceAlreadyExistsError: If a namespace with the given name already exists.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace_exists(namespace):\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NamespaceAlreadyExistsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNamespace \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnamespace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m properties:\n\u001b[1;32m    530\u001b[0m     properties \u001b[38;5;241m=\u001b[39m IcebergNamespaceProperties\u001b[38;5;241m.\u001b[39mNAMESPACE_MINIMAL_PROPERTIES\n",
      "\u001b[0;31mNamespaceAlreadyExistsError\u001b[0m: Namespace default already exists"
     ]
    }
   ],
   "source": [
    "catalog.create_namespace(\"default\")\n",
    "\n",
    "table = catalog.create_table(\n",
    "    \"default.taxi_dataset\",\n",
    "    schema=df.schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.create_table(\n",
    "    \"default.ducks\",\n",
    "    schema=df.schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.append(df)\n",
    "len(table.scan().to_arrow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.compute as pc\n",
    "\n",
    "df = df.append_column(\"tip_per_mile\", pc.divide(df[\"tip_amount\"], df[\"trip_distance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with table.update_schema() as update_schema:\n",
    "    update_schema.union_by_name(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.overwrite(df)\n",
    "print(table.scan().to_arrow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2371784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = table.scan(row_filter=\"tip_per_mile > 0\").to_arrow()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x1375f3230>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.execute(\"\"\"\n",
    "    INSTALL iceberg;\n",
    "    LOAD iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: Cannot open file \"/Users/matthewmartin/dream_machine/iceberg/pyicy/icehouse/default.db/taxi_dataset/metadata/v2.metadata.json\": No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mSELECT COUNT(*)\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mFROM iceberg_metadata(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/matthewmartin/dream_machine/iceberg/pyicy/icehouse/default.db/taxi_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, allow_moved_paths= true)\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#/Users/matthewmartin/dream_machine/iceberg/pyicy/icehouse/default.db/taxi_dataset\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: Cannot open file \"/Users/matthewmartin/dream_machine/iceberg/pyicy/icehouse/default.db/taxi_dataset/metadata/v2.metadata.json\": No such file or directory"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM iceberg_metadata('/Users/matthewmartin/dream_machine/iceberg/pyicy/icehouse/default.db/taxi_dataset', allow_moved_paths= true)\n",
    "\"\"\"\n",
    "\n",
    "#/Users/matthewmartin/dream_machine/iceberg/pyicy/icehouse/default.db/taxi_dataset\n",
    "\n",
    "cn.sql(sql).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
