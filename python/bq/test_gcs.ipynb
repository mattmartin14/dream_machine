{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"GBQ_PROJECT_ID\")\n",
    "bucket_nm = os.getenv(\"GCS_BUCKET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcs_uris_to_load(bucket_nm, prefix) -> list:\n",
    "    gcs_client = storage.Client(project_id)\n",
    "    bucket = gcs_client.get_bucket(bucket_nm)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "    # only grab parquet files\n",
    "    gcs_uris = [blob.public_url for blob in blobs if blob.name.endswith('.parquet')]\n",
    "\n",
    "    return gcs_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bq_from_gcs(gcs_uris, dataset_nm, table_nm) -> None:\n",
    "    table_id = f\"{project_id}.{dataset_nm}.{table_nm}\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.PARQUET\n",
    "    )\n",
    "\n",
    "    bq_client = bigquery.Client(project_id)\n",
    "    job = bq_client.load_table_from_uri(\n",
    "        gcs_uris,\n",
    "        table_id,\n",
    "        job_config=job_config,\n",
    "    ).result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"test_files/par\"\n",
    "gcs_uris = get_gcs_uris_to_load(bucket_nm, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_bq_from_gcs(gcs_uris, \"sandbox\", \"test_internal_from_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_gcs(local_file_path, gcs_bucket_name, gcs_key_path):\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(gcs_bucket_name) \n",
    "    blob = bucket.blob(gcs_key_path)\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "    print(\"file {0} uploaded successfully\".format(os.path.basename(local_file_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_gcs_v2(local_file_path):\n",
    "    gcs_bucket_name = \"data-mattm-test-sbx\"\n",
    "    gcs_key_path = \"test_files/\"+os.path.basename(local_file_path)\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(gcs_bucket_name) \n",
    "    blob = bucket.blob(gcs_key_path)\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "    print(\"file {0} uploaded successfully\".format(os.path.basename(local_file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import glob\n",
    "\n",
    "local_folder_path = os.path.expanduser(\"~/test_dummy_data/gcs/*.csv\")\n",
    "gcs_bucket_name = \"data-mattm-test-sbx\"\n",
    "\n",
    "csv_files = glob.glob(local_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_files/test8.csv\n",
      "file test8.csv uploaded successfully\n",
      "test_files/test9.csv\n",
      "file test9.csv uploaded successfully\n",
      "test_files/test4.csv\n",
      "file test4.csv uploaded successfully\n",
      "test_files/test5.csv\n",
      "file test5.csv uploaded successfully\n",
      "test_files/test7.csv\n",
      "file test7.csv uploaded successfully\n",
      "test_files/test6.csv\n",
      "file test6.csv uploaded successfully\n",
      "test_files/test2.csv\n",
      "file test2.csv uploaded successfully\n",
      "test_files/test3.csv\n",
      "file test3.csv uploaded successfully\n",
      "test_files/test1.csv\n",
      "file test1.csv uploaded successfully\n",
      "test_files/test10.csv\n",
      "file test10.csv uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "gcs_bucket_name = \"data-mattm-test-sbx\"\n",
    "for local_file_path in csv_files:\n",
    "    gcs_key_path = \"test_files/\"+os.path.basename(local_file_path)\n",
    "    print(gcs_key_path)\n",
    "    upload_file_to_gcs(local_file_path, gcs_bucket_name, gcs_key_path)\n",
    "\n",
    "    #futures.append(executor.submit(upload_file_to_gcs, local_file_path, gcs_bucket_name, gcs_key_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file test8.csv uploaded successfullyfile test5.csv uploaded successfully\n",
      "file test6.csv uploaded successfully\n",
      "file test2.csv uploaded successfully\n",
      "file test7.csv uploaded successfully\n",
      "\n",
      "file test1.csv uploaded successfully\n",
      "file test4.csv uploaded successfully\n",
      "file test3.csv uploaded successfully\n",
      "file test10.csv uploaded successfully\n",
      "file test9.csv uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import glob\n",
    "\n",
    "local_folder_path = os.path.expanduser(\"~/test_dummy_data/gcs/*.csv\")\n",
    "gcs_bucket_name = \"data-mattm-test-sbx\"\n",
    "\n",
    "csv_files = glob.glob(local_folder_path)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    executor.map(upload_file_to_gcs_v2, csv_files)\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "#     futures = []\n",
    "#     for local_file_path in csv_files:\n",
    "#         gcs_key_path = \"test_files/\"+os.path.basename(local_file_path)\n",
    "#         futures.append(executor.submit(upload_file_to_gcs, local_file_path, gcs_bucket_name, gcs_key_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_gcs_v2(local_file_path):\n",
    "    gcs_bucket_name = \"data-mattm-test-sbx\"\n",
    "    gcs_key_path = \"test_files/\"+os.path.basename(local_file_path)\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(gcs_bucket_name) \n",
    "    blob = bucket.blob(gcs_key_path)\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "    print(\"file {0} uploaded successfully\".format(os.path.basename(local_file_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error: A process in the process pool was terminated abruptly while the future was running or pending.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-45:\n",
      "Process SpawnProcess-43:\n",
      "Process SpawnProcess-41:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-42:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-46:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'upload_file_to_gcs_v2' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'upload_file_to_gcs_v2' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'upload_file_to_gcs_v2' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-44:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'upload_file_to_gcs_v2' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'upload_file_to_gcs_v2' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'upload_file_to_gcs_v2' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import glob\n",
    "\n",
    "\n",
    "local_folder_path = os.path.expanduser(\"~/test_dummy_data/gcs/*.csv\")\n",
    "gcs_bucket_name = \"data-mattm-test-sbx\"\n",
    "\n",
    "csv_files = glob.glob(local_folder_path)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(upload_file_to_gcs_v2, local_file_path) for local_file_path in csv_files]\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
