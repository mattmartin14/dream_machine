{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mimesis\n",
    "# %pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from mimesis import Person, Address, Numeric\n",
    "import polars as pl\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out datasets\n",
    "def generate_datasets(batch_nbr: int) -> None:\n",
    "    peep = Person()\n",
    "    adrs = Address()\n",
    "    num = Numeric()\n",
    "\n",
    "    data = []\n",
    "    for _ in range(1_000_000):\n",
    "        data.append({'first_name':peep.first_name(), 'last_name':peep.last_name()\n",
    "                    , 'address_txt':adrs.address(), 'zip_cd':adrs.zip_code()\n",
    "                    , 'city':adrs.city(), 'state':adrs.state()\n",
    "                    , 'net_worth': num.integer_number(0,50000)})\n",
    "        \n",
    "    pl.DataFrame(data).write_csv(f'~/test_dummy_data/polars/data{batch_nbr}.csv')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets_parallel(num_batches: int, max_workers: int) -> None:\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        executor.map(generate_datasets, range(num_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() \n",
    "generate_datasets_parallel(10, 3)\n",
    "end_time = time.time()  # Record the end time\n",
    "total_time = end_time - start_time  # Calculate the total time taken\n",
    "print(f\"Total time taken: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pl.read_csv('~/test_dummy_data/polars/data*.csv')\n",
    "\n",
    "\n",
    "## TODO: Aggregate data up, add timestamp column, write to parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.group_by(\"zip_cd\").agg(\n",
    "     pl.col(\"net_worth\").sum().name.suffix(\"_tot\")\n",
    "    ,pl.col(\"first_name\").n_unique().name.suffix(\"_cnt\")\n",
    "    ,pl.col(\"city\").count().alias(\"city_cnt\")\n",
    ")\n",
    "\n",
    "df2.head(5)\n",
    "df2.write_csv(file=\"~/test.csv\",include_header=True, separator=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
